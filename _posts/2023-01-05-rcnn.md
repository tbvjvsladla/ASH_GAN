---
layout: post
title:  "RCNN 논문 리뷰"
comments: true
tags: [RCNN]
---

RCNN 논문리뷰
===


Rich feature hierarchies for accurate object detection and semantic segmentation Tech report (v5)


abstract
---
객체 감지 성능에 있어, `PASCAL VOC`데이터 세트를 활용해 측정한 성능은 몇년간 정체상태였으며, 가장 성능이 좋은 방법은 여러 하위 이미지 feature와 상위레벨의 context를 결합하는 앙상블 시스템을 구성하는 것이다.   
본 논문은 mean average precision(mAP) 측정 지표에 있어 VOC 2012 결과값 대비 30%이상 개선된(mAP가 53.3%로 측정됨) 탐지 알고리즘을 제안한다.   
논문의 접근방식은 아래와 같다.   
1. obj를 segment하고 localize하기 바텀-업 방식의 제안영역에 높은 용량을 갖는 CNNs을 적용할 수 있다
2. 훈련을 위한 데이터가 라벨링이 덜 됬을 때, 사전 지도학습(supervised pre-training)을 보조작업으로 도메인별 파인튜닝을 수행해 성능 향상을 가져올 수 있다.


논문은 이 방법을 R-CNN : Regions with CNN이라 부르려 한다  
제안한 RCNN을 ILSVERC2013에서 발표된 OverFeat랑 비교해보니 성능이 더 좋앗다.
      





introduction
---

기존 시각 인식 작업(visual recognition task)는 지난 10년간 SIFT, HOG사용을 기반으로 하고 있다.
그러나, PASCAL VOC Obj detection성능을 보면 일반적으로 10~12년 동안 앙상블 시스템 구축 프로세스를 기반으로 진행되어왔고 해당 방식으로 조금씩의 진보가 이뤄지고 있었다.   

* SIFT(Scale Invariant Feature Transform)
  * 이미지에서 특징점을 추출하는 대표적 알고리즘 중 하나임.   
이미지의 Scale, Rotation에 불변하는 feature(특징)을 찾아냄.

```python
import numpy as np
import cv2
from matplot import pyplot as plt

img1 = cv2.imread('falsify_img.jpg') #변조된 이미지
img2 = cv2.imread('orign_img.jpg') #원본 이미지

sift = cv2.xfeature2d.SIFT_create()
#SIFT 추출기 생성

kp1, des1 = sift.detectAndCompute(img1, None)
#키 포인트 검출과 서술자 계산 -> 이미지 1에 대한
kp2, des2 = sift.detectAndCompute(img2, None)

bf = cv2.BFMacher(cv2.NORM_HAMMING, crossCheck=Ture)
#매칭을 위한 변수 만들고 초기화

matches = bf.match(des1, des2) #매칭 시작
matches = sorted(matches, key = lambda x:x.distance)
#매칭된 특징점들을 길이별로 정렬함

img3 = cv2.drawMatches(img1, kp1, img2, kp2, matches[:10], flags=2)
#이미지1, 이미지2의 매칭결과를 키 포인트와 함께 새로 그림을 그려서 보여줌
plt.imshow(img3)
plt.show()
```
대략 아래와 같은 그림이 그려질 것임
![img](../images/43a91beeccc4732597f035ff55f22db2.jpg)

* HOG(Histograms of oriented gradient)
  * 사전 지식으로 edge 검출부터 알아야함   
우선 edge검출의 경우 픽셀의 변화량이 큰 지점을 엣지라 볼 수 있음   
여기서 Histogram of gradient는 이 픽셀의 변화량을 화살표로 표시하여,
화실표를 히스토그램 형태의 feature를 추출하는 방법을 말함

![img2](../images/2093023.png)

  * 이때 화살표를 그리는 방식에 Gradient orientation(화살표 방향), Gradient magnitude(화살표 크기) 두가지 정보를 만들어 낼 수 있음    
이 두가지 정보를 이용해서 HoG를 구하고 이거로 경계면을 추출해 사람이나 차선등을 구분할 수 있음

![img3](../images/wprVEuJ.png)

  * 사전 지식으로 pixels, cells, blocks, windows의 개념에 대해 알아야 한다.   
픽셀(pixels) : 말 그대로 영상 내 하나의 픽셀 값   
셀(Cells) : 픽셀을 몇개 묶어서 그룹화 한 것   
block : 셀을 묶어서 그룹화 한 것   
window : 검출하고자 잘라낸 영역(블록보다는 크다)   

  * 그렇다면 HOG는 보행자 검출을 위해 만들어진 특징 디스크립터라 볼 수 있으며, 이것에 대한 방식으로 기울기 벡터 크기(magnitude)와 방향(direction)을 히스토그램으로 나타내 계산한 것이다.

```python
img = cv2.imread('img.png')
img = np.float(img)

gx = cv2.Sobel(img, cv2.CV_32F, 1, 0)
gy = cv2.Sobel(img, cv2.CV_32F, 0, 1)
#소벨필터를 활용해 32float 데이터 타입으로 x방향, y방향으로 각각 1차미분
magnitude, angle = cv2.cartToPolar(gx, gy)
#앞에서 편미분 결과 gx, gy를 극좌표로 전환 -> 방향벡터의 크기 및 방향 추출
```
위 계산 후 정규화(normalization)과정을 수행하여 윈도에 대한 히스토그램 특징이 계산된다면 이것과 유사한 정규화 값을 결과값은 검출하고자 하는 대상이라 볼 수있다.   
이것을 OpenCV에서는 HOG 디스크립터 계산을 위한 함수를 따로이 제공한다.   


```python
import cv2

#default 디텍터를 위한 HOG 객체 생성 및 설정
hogdef = cv2.HOGDescriptor()
hogdef.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())

#dailer 디텍터를 위한 HOG 객체 생성 및 설정
hogdaim = cv2.HOGDescriptor((48, 96), (16, 16), (8,8), (8,8), 9)
#파라미터 : 윈도 크기, 블록 크기, 정규화 블록 겹침 크기, 셀 크기, 히스토그램 계급 수
hogdaim.setSVMDetector(cv2.HOGDescriptor_getDaimlerPeopleDetector())

cap = cv2.VideoCapture('../img/walking.avi')
mode = True #모드 변환을 위한 플래그 변수
while cap.isOpened():
    ret, img = cap.read()
    if ret :
        if mode:
            # default 디텍터로 보행자 검출
            found, _ = hogdef.detectMultiScale(img)
            for (x,y,w,h) in found:
                cv2.rectangle(img, (x,y), (x+w, y+h), (0,255,255))
        else:
            # daimler 디텍터로 보행자 검출
            found, _ = hogdaim.detectMultiScale(img)
            for (x,y,w,h) in found:
                cv2.rectangle(img, (x,y), (x+w, y+h), (0,255,0))
        cv2.putText(img, 'Detector:%s'%('Default' if mode else 'Daimler'), \
                        (10,50 ), cv2.FONT_HERSHEY_DUPLEX,1, (0,255,0),1)
        cv2.imshow('frame', img)
        key = cv2.waitKey(1) 
        if key == 27:
            break
        elif key == ord(' '):
            mode = not mode
    else:
        break
cap.release()
cv2.destroyAllWindows()
```

여기까지가 SIFT, HOG설명이다....

